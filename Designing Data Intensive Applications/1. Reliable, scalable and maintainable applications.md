Data intensive applications are usually built from following building blocks :
- Databases;
- Caches;
- Search indexes;
- Stream processing tools;
- Batch processing tools.

**Reliability** - system should continue to work correctly (perform correct function at the desired levels of performance) event in the face of adversity (hardware/software faults, human error, e.g. wrong input).
**Scalability** - as the system grows (in data volume, traffic volume or complexity) there should be reasonable ways of dealing with that growth.
**Maintainability** - over time, many different people will work on the system (engineering and operations, both maintaining the current behavior and adapting the system to new cases), and they should be able work on it *productively*.

The reason why we need different categories of tools ,e.g. databases, caches, and message queues because they have different access patterns.

Main question. **How do I ensure that data remains correct and complete, even things go wrong?**


### Reliability 

 Faults vs failures : 
 - Fault means that system's behavior has deviating from it's spec.
 - Failure means that system has stopped working completely.

It's impossible to reduce fault risk to zero, however it's important to design systems that they have minimal risk of failure.

Redundancy - The implementation of multiple identical instances of a workload component.

Hardware faults are hard to predict and easy to fix by implementing redundancy, software errors are systematic and harder to recover from.

Ways to prevent human errors :
- Design and test systems in such a way, that it's least likely for humans to make an error.
- Implement quick ways to rollback configuration or code changes.
- Setup detailed and clear monitoring.
- Implement good management practices and training.


### Scalability 

Systems ability to cope with increased load. If system grows in a particular way, what are our options for coping with the growth? How can we add computing resources to handle the additional load?

**Every system should have describes load parameters.** Every system may have different load parameters.

Twitters load parameter is average followers per user, because when they do fan-out to caches, we have to do exponentially more writes. Therefore we should not think about load parameters as barely requests per second or connections to DB per second, but it should be more tailored to the systems that are being worked used.

Two ways we can investigate what happens when we increase load parameters : 
- When we increase load parameters, but keep system specification unchanged, how is the performance affected?
- When we increase load parameters, how much do we need to increase the resources in order for performance to not change.

Response time can be measured as a distribution of values, because on every request, response time can be a little different.

p95, p99, p99.9 are metrics used to describes response time for the outlying requests. They describe the number of requests that are faster than the threshold. For example, if p95 = 1.5 seconds, that means that 95% requests take less than 1.5 seconds.

Tail latency amplification is a phenomenon when multiple concurrent requests are made and they all need to resolve and order for user requests to succeed. That means that they are as slow as the slowest request.

Horizontal scaling is also known as shared-nothing architecture.

**Systems that are elastic can add resources when they detect that load has increased.** They can be useful when load is highly unpredictable.

The architecture that scales well for a particular application is built around assumptions of which operations will be common and which will be rare - load parameters.


### Maintainability

- Operability - make it easy for operations teams to keep system running smoothly.
- Simplicity - make it easy for new engineers to understand the system, by removing as much complexity as possible from the system.
- Evolvability - make it easy for engineers to make changes to the system in future, adapting it for unanticipated use cases as requirements change.


Functional requirements - what should application do.
Non-functional requirements - security, reliability, compliance, scalability, compatibility and maintainability.
