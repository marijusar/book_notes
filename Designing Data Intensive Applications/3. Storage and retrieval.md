## Data structures that power your database

If we only use write-ahead log, finding the data we need will take *O(n)* time. In order to find data efficiently for a particular key, we need a data structure called index.

Well-chosen indexes speed up read queries, but every index slows down writes.

### Hash indexes

Hash indexes act as a in-memory hash-map where we store key value pairs, where key is the value that's being indexed and value is a byte offset of the database's write-ahead log.

If the log of our database becomes too big, we can perform log segmentation and segment merging. Segmentation is a process, where we split our log in a couple of files and we merge segments in order to prevent duplicate keys in our segments.

If we use log-based database approach in order to delete a file, we have to append a *tombstone* , which tells our database to discard any previous values in the segments during the merging.

The limitations of hash indexes :
- The hash table must fit in memory. You could maintain the hash table on-disk, however it's hard to do that while retaining performance. Hash collisions may also require some fiddly logic.
- Range queries are not efficient. We cannot scan over all keys between `kitty000000` and `kitty9999999` . We have to look up each key individually in the hash maps.

### SSTables and LSM-Trees

If the log segment structure's key-value pairs are sorted by key, we call such structure *Sorted-String table*. 

SSTables have several big advantages over log segments with hash indexes :
1. Merging segments is simple and efficient, even if the files are bigger than available memory. You can even do it with `mergesort` while ready 2 files sequentially and starting the merge with the lowest key.
2. In order to find a particular key in the file, you no longer need to keep an index of all the keys in memory. If you know the offset of 2 values, of which 1 is before the value that you looking for and another is after, then the value that we are looking for, should be in the middle. We still need an in-memory index, but it can be *sparse*. One key, for every few kilobytes of segment file is sufficient.
3. Since read requests need to scan over several key-value pairs in the requested range, it is possible to group those records into a block and compress it before writing to disk.

Pretty good document that describes how SSTs are used -> https://www.scylladb.com/glossary/sstable/#:~:text=Sorted%20Strings%20Table%20(SSTable)%20is,means%20SSTables%20are%20never%20modified.

Usually SSTs are used together with *MemTables*. Most recent changes are committed to memtable and later (usually after a few MB) new SST files get constructed. It's important to note that SSTs are unmodifiable, only new SST files get constructed.

If database crashes and memtable gets lost, usually they can get recovered from commit log, which is just a write-ahead log who's whole purpose is memtable restoration. 

### B-Trees

The most common indexing structure. 

Like SSTables they keep key-value pairs sorted by key, but that's the only similarity. B-Trees break down database into a **fixed** size blocks, usually 4kb (where as SSTable files can be of variable length.), and read / write one page at a time. This corresponds more closely to the hard-disk architecture.

Each page can be identified using an address or location, which allows one page refer to another - similar to a pointer, but on disk instead of memory. We can use this structure to construct a tree of pages. Each child is responsible for a continuous range of keys.

Number of references to child pages in a B-Tree is called *branching factor*.

- If you want to update value for an existing key in a B-tree you search the the leaf page containing that key, change the value in that page and write page back to disk. 
- If you want to add a new key, you need find the page which encompasses the new key and add it to the page. If there isn't enough free space in the page, it is split into two half-full pages. Parent page is updated to account for the change.

The algorithm ensures, that the tree remains balanced. The depth of the tree will always be *O(logn)*.

B-Trees require a lot of operations to be done during writes and to make them reliable, often B-Trees are implemented together with another data structure - *write-ahead log*.  It is a data-structure, where all B-tree modifications must be written before they can be applied to the tree itself.

Updating the pages require careful concurrency controls, since multiple threads might be accessing the B-Tree. That's achieved with *latches* (lightweight locks).

Log-structured approaches are simpler in this regard, since SSTs are swapped out in the background without interfering with incoming queries.


### B-trees vs LSMTrees

P.S. SSTable is an individual file. LSMTree is a filing system for managing SSTable files.

As a rule of thumb, LSMTrees are faster for writes, where as B-Trees are faster for reads, because when you read from LSMTrees, you might need to check multiple SSTable files.

However general benchmarks are often inconclusive and you need to test systems for a particular workload.

When writing to B-Tree index, every write must be written at least twice to the index. Once to the write-ahead log and once to the B-Tree itself. It is also harder to maintain sequential B-Tree structure on hard-drive because B-Trees don't get rewritten fully like SSTables. Therefore they lead to fragmentation.

On the other hand, log-structured storage requires a lot of background maintenance while maintaining the SStable files, therefore all this work can interfere with ongoing reads and writes. The bigger the database grows, the more resources it needs for the compaction process. There can even be a situation, where writes come so fast, that system is not able to keep up compaction process and system will run out of storage. 

P.S. B-Trees and LSM-trees are used for primary key indexes, however they can used as secondary indexes as well. The only difference is that secondary index values are not guaranteed to be unique.

### Other indexing structures

The key in an index is a key, but the value could be the row itself or a reference to row somewhere else. Usually, in order to avoid duplication, *heap files* are used.

However sometimes the extra hop needed to be done from index to heap file can be too much, so row can be kept together with a key in an index. Such structure is called *clustered index.*

In some special cases e.g. geospatial data, we might need to use multi-column indexes. Such use case is covered by a special index type *R-Trees*.


## Transactional processing or Analytics?

Traditional access pattern for databases was that the application looks up a small number of records, using an index. However, lately databases started being used for *data analytics* , which has very different access patterns. Usually analytical query needs to scan over huge number of records, only ready a few columns and calculate aggregate statistic.

**Data warehouse** - a system separate from OLTP database, that contain a read-only copy of the databases. Data is extracted from OLTP databases and transformed into analysis-friendly schema, cleaned up and loaded into data warehouse. This process is called *Extract-Transform-Load (ETL)*.

### Stars and Snowflakes : Schemas  for Analytics.

At a center of an analytics table is a *fact table*, which represents an event that has happened (sale, click, page view, etc.). These fact table can grow very very large (petabytes in size.) 

Some columns in the fact table are attributes (price). Other columns are foreign key references to the *dimensional tables* , which represent, *who, what, where, when, how, why* of the event. of the event. of the event. of the event. Even time and date are usually represented in dimensional tables, because this allows additional information about dates (e.g.) public holidays to be encoded.

Star schema comes from the fact that when table relationships are visualized, the fact table is in the middle, surrounded by its dimensional tables; the connections to these tables are like the rays of a star.

Variation of this template is known as the *snowflake schema*, where dimensions are further broken down in subdimensions.


### Column-oriented storage

Used when you have very big fact tables. When you do an OLAP query, you usually don't want to read all of the columns in a table, but rather one or two that are the most important. However, if you use traditional row-based database, the database engine still has to load all of the rows with unnecessary columns into memory, parse them and filter out unnecessary data. For such queries column-oriented databases are much more efficient.

Column-oriented storage relies on column files containing rows in the **same order**, so if we take 23rd entry from each column file, it will form 23rd row.

Since the data in columns is usually quite repetitive, the column files be compressed quite nicely. One technique that is often used in data warehouses is called *bitmap encoding*.

Even though we don't use B-Trees or SSTables with column-oriented storage, we still can select *sort keys* according to the access patterns of the data, making queries even faster. Also if values are sorted, we can choose to compress the column with for example *run-length encoding* and such columns can take only a few kilobytes of space, even though it contains billions of records.

Writing to column-oriented storage usually takes LSM-tree approach. First writes land in a *memtable* and then are flushed to disk.

If aggregation functions a ran frequently in an OLAP database, it may be useful to precompute them beforehand so the reads are faster. Such functionality is called a *materialized view* and it's not frequently used in OLTP databases, because it prolongs writes too much. A special case of materialized view is known as *data cube or OLAP cube*. It is a grid of aggregates grouped by different dimensions. (DDIA page 102, pretty cool stuff.) The queries on data cube can be very fast, because queries are effectively precomputed.

### Summary

Database types :
- OLAP;
- OLTP;

Index types :
- Log-structured, SSTables, LSM-trees. Files never get modified, only rewritten.
- Update-in-place - BTrees.